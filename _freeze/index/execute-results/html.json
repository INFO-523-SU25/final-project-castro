{
  "hash": "8623e18445757ec628112fcbf33750c9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Uncovering Patterns and Anomalies in Manufacturing Data\"\nsubtitle: \"INFO 523 - Final Project\"\nauthor: \n  - name: \"Cesar Castro\"\n    affiliations:\n      - name: \"College of Information Science, University of Arizona\"\ndescription: \"Project description\"\nformat:\n   html:\n    code-tools: true\n    code-overflow: wrap\n    embed-resources: true        \neditor: visual\nexecute:\n  warning: false\n  echo: false\njupyter: python3\n---\n\n## Abstract\n\n<p style=\"text-align: justify;\">\n\nIn recent decades, industry continues modernizing processes and equipment. This is creating enormous amounts of data that in many cases might be underutilized. Vast and rich data from machines, like temperatures, vibration, and pressure, are constantly monitored. Traditional statistical process control is vastly used to oversee key process parameters and provide feedback to technicians when something might be behaving abnormally. In recent years, with the explosion of AI, industry has been looking at different approaches to monitor these parameters and use different techniques to more effectively predict or detect defects in products or problems in the machines.\n\n</p>\n\n<p style=\"text-align: justify;\">\n\nThis study focuses on using machine learning algorithms like random forest and gradient boosting to predict failures and the type of failure. Real factory data has noise, interactions with many factors, and is highly imbalanced. Machines are expected to run all the time without failure, and processes ideally will produce products without any defects, which makes data highly skewed toward a good state and just a few failures. Tuning models to handle this imbalance is critical in the factories. Different sampling methods were evaluated: creating synthetic data to over-sample the negative, under-sampling the positive, and giving weights are approaches that can be used.\n\n</p>\n\n<p style=\"text-align: justify;\">\n\nA second study was done on time-series data, where algorithms like ARIMA and LSTM were used to detect outliers over time. One big challenge is that manufacturing KPIs are typically centered around a target, and variation is random, ideally following a normal distribution but not necessarily following a pattern, which limits the use of these algorithms to predict results. However, results can still be used to detect outliers, but this might not be the best approach.\n\n</p>\n\n## Background\n\n<p style=\"text-align: justify;\">\n\nTo explore machine algorithms to detect fails, a dataset from Kaggle was used. The data \"[Machine Predictive Maintenance Classification](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification) is a synthetic dataset that reflects a real use case in the industry, based on the source. The dataset consists of 10000 rows with 14 different features.\n\n</p>\n\nKey Features: (Source: <https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification>)\n\n-   UID: unique identifier ranging from 1 to 10000\n\n-   productID: consisting of a letter L, M, or H for low (50% of all products), medium (30%), and high (20%) as product quality variants and a variant-specific serial number\n\n-   Type: is a columns that consist only on the letters L, M and H from productID.\n\n-   air temperature \\[K\\]: generated using a random walk process later normalized to a standard deviation of 2 K around 300 K\n\n-   process temperature \\[K\\]: generated using a random walk process normalized to a standard deviation of 1 K, added to the air temperature plus 10 K.\n\n-   rotational speed \\[rpm\\]: calculated from powepower of 2860 W, overlaid with a normally distributed noise\n\n-   torque \\[Nm\\]: torque values are normally distributed around 40 Nm with an Ïƒ = 10 Nm and no negative values.\n\n-   tool wear \\[min\\]: The quality variants H/M/L add 5/3/2 minutes of tool wear to the used tool in the process.\n\n-   Machine failure: label that indicates, whether the machine has failed in this particular data point for any of the following failure modes are true\n\n::: {#c8fd7c78 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UDI</th>\n      <th>Product ID</th>\n      <th>Type</th>\n      <th>Air temperature [K]</th>\n      <th>Process temperature [K]</th>\n      <th>Rotational speed [rpm]</th>\n      <th>Torque [Nm]</th>\n      <th>Tool wear [min]</th>\n      <th>Target</th>\n      <th>Failure Type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>M14860</td>\n      <td>M</td>\n      <td>298.1</td>\n      <td>308.6</td>\n      <td>1551</td>\n      <td>42.8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>No Failure</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>L47181</td>\n      <td>L</td>\n      <td>298.2</td>\n      <td>308.7</td>\n      <td>1408</td>\n      <td>46.3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>No Failure</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>L47182</td>\n      <td>L</td>\n      <td>298.1</td>\n      <td>308.5</td>\n      <td>1498</td>\n      <td>49.4</td>\n      <td>5</td>\n      <td>0</td>\n      <td>No Failure</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>L47183</td>\n      <td>L</td>\n      <td>298.2</td>\n      <td>308.6</td>\n      <td>1433</td>\n      <td>39.5</td>\n      <td>7</td>\n      <td>0</td>\n      <td>No Failure</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>L47184</td>\n      <td>L</td>\n      <td>298.2</td>\n      <td>308.7</td>\n      <td>1408</td>\n      <td>40.0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>No Failure</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n**Table1**: Example of 5 rows of the synthetic data used for predictive modeling.\n\n::: {#cell-PMdata2 .cell message='false' execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata2-output-1.png){#pmdata2}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcess temperature [K] Mean: 310.01\nProcess temperature [K] Median: 310.10\nProcess temperature [K] Max: 313.80\nProcess temperature [K] Min: 305.70\nProcess temperature [K] Standard Deviation: 1.48\nProcess temperature [K] Number of Points: 10000\n```\n:::\n:::\n\n\n**Figure 1**: Example of the distribution observed for 1 synthetic parameters (Process Temperature). Visually data seems not having a significant skew, relatively close to a normal distribution.\n\n::: {#cell-PMdata3 .cell message='false' execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata3-output-1.png){#pmdata3}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRotational speed [rpm] Mean: 1538.78\nRotational speed [rpm] Median: 1503.00\nRotational speed [rpm] Max: 2886.00\nRotational speed [rpm] Min: 1168.00\nRotational speed [rpm] Standard Deviation: 179.28\nRotational speed [rpm] Number of Points: 10000\n```\n:::\n:::\n\n\n**Figure 2**: Example of the distribution observed for 1 synthetic parameters (Rotational speed \\[rpm\\]). On this case data is slightly skewed which in some cases is expected for real machine data.\n\n<p style=\"text-align: justify;\">\n\nTable 1 and Figure 1 are examples of how data looks like, there are no missing data on this set as it was synthetically created which is not normal on a real scenario. Figure 2 shows another parameter where data is skewed. Observing all parameters, dataset is a good representation to explore machine learning algorithms and able to reach conclusions out of the analysis.\n\n</p>\n\nAll detailed data cleaning and exploration can be found here: <https://github.com/INFO-523-SU25/final-project-castro/blob/main/src/Data_Exploration_PDM.ipynb>\n\n<p style=\"text-align: justify;\">\n\nThe second dataset consists of a simulated real-time sensor data from industrial machines. Source is also from Kaggle and it can be found here: <https://www.kaggle.com/datasets/ziya07/intelligent-manufacturing-dataset/data>\n\n</p>\n\nKey Features:\n\n-   Industrial IoT Sensor Data\n\n    -   Temperature_C, Vibration_Hz, Power_Consumption_kW,\n\n-   Network Performance:\n\n    -   Network_Latency_ms, Packet_Loss\\_%, Quality_Control_Defect_Rate\\_%\n\n-   Production Indicators:\n\n    -   Production_Speed_units_per_hr, Predictive_Maintenance_Score, Error_Rate\\_%\n\n-   Target Column Efficiency_Status\n\n::: {#81d136b9 .cell execution_count=4}\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Timestamp</th>\n      <th>Machine_ID</th>\n      <th>Operation_Mode</th>\n      <th>Temperature_C</th>\n      <th>Vibration_Hz</th>\n      <th>Power_Consumption_kW</th>\n      <th>Network_Latency_ms</th>\n      <th>Packet_Loss_%</th>\n      <th>Quality_Control_Defect_Rate_%</th>\n      <th>Production_Speed_units_per_hr</th>\n      <th>Predictive_Maintenance_Score</th>\n      <th>Error_Rate_%</th>\n      <th>Efficiency_Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-01-01 00:00:00</td>\n      <td>39</td>\n      <td>Idle</td>\n      <td>74.137590</td>\n      <td>3.500595</td>\n      <td>8.612162</td>\n      <td>10.650542</td>\n      <td>0.207764</td>\n      <td>7.751261</td>\n      <td>477.657391</td>\n      <td>0.344650</td>\n      <td>14.965470</td>\n      <td>Low</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-01-01 00:01:00</td>\n      <td>29</td>\n      <td>Active</td>\n      <td>84.264558</td>\n      <td>3.355928</td>\n      <td>2.268559</td>\n      <td>29.111810</td>\n      <td>2.228464</td>\n      <td>4.989172</td>\n      <td>398.174747</td>\n      <td>0.769848</td>\n      <td>7.678270</td>\n      <td>Low</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-01-01 00:02:00</td>\n      <td>15</td>\n      <td>Active</td>\n      <td>44.280102</td>\n      <td>2.079766</td>\n      <td>6.144105</td>\n      <td>18.357292</td>\n      <td>1.639416</td>\n      <td>0.456816</td>\n      <td>108.074959</td>\n      <td>0.987086</td>\n      <td>8.198391</td>\n      <td>Low</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-01-01 00:03:00</td>\n      <td>43</td>\n      <td>Active</td>\n      <td>40.568502</td>\n      <td>0.298238</td>\n      <td>4.067825</td>\n      <td>29.153629</td>\n      <td>1.161021</td>\n      <td>4.582974</td>\n      <td>329.579410</td>\n      <td>0.983390</td>\n      <td>2.740847</td>\n      <td>Medium</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-01-01 00:04:00</td>\n      <td>8</td>\n      <td>Idle</td>\n      <td>75.063817</td>\n      <td>0.345810</td>\n      <td>6.225737</td>\n      <td>34.029191</td>\n      <td>4.796520</td>\n      <td>2.287716</td>\n      <td>159.113525</td>\n      <td>0.573117</td>\n      <td>12.100686</td>\n      <td>Low</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n**Table 2**: Example of 5 rows of the synthetic data that will be used for time series analysis.\n\n::: {#cell-PMdata5 .cell message='false' execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata5-output-1.png){#pmdata5}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nPower_Consumption_kW Mean: 5.75\nPower_Consumption_kW Median: 5.76\nPower_Consumption_kW Max: 10.00\nPower_Consumption_kW Min: 1.50\nPower_Consumption_kW Standard Deviation: 2.45\nPower_Consumption_kW Number of Points: 100000\n```\n:::\n:::\n\n\n**Figure 3**: Example of the distribution observed on second dataset for parameter Power_Consumption_kW. Data does not follow a specific distribution, it seems randomly created over a specific range.\n\n<p style=\"text-align: justify;\">\n\nIs it can be observed on Figure 3, the data from the the second dataset seems more randomly created without following a specific distribution. Data in a real scenario for a machine typically follows some type of distribution and it's not completely random, a common situation is that processes typical have a target value or values over time and there is some natural variation around it. The raw data as it is from this source is not usable for the intend of this study. In order to make data more like real scenario a mean was calculated per every 12 hours.\n\n</p>\n\n<p style=\"text-align: justify;\">\n\nResults from the data transformation using the mean for blocks of 12 hours can be observed in figures 4 and 5.\n\n</p>\n\n::: {#cell-PMdata6 .cell message='false' execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata6-output-1.png){#pmdata6}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nPower_Consumption_kW Mean: 5.74\nPower_Consumption_kW Median: 5.75\nPower_Consumption_kW Max: 8.29\nPower_Consumption_kW Min: 2.96\nPower_Consumption_kW Standard Deviation: 0.67\nPower_Consumption_kW Number of Points: 6950\n```\n:::\n:::\n\n\n**Figure 4**: Example of the distribution for the result of grouping the data every 12 hours and calculating the mean for each group.\n\n::: {#cell-PMdata7 .cell message='false' execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata7-output-1.png){#pmdata7}\n:::\n:::\n\n\n**Figure 5**: Example Trend for Power_Consumption_kW for one of the machines.\n\nAll detailed data cleaning and exploration for the second dataset can be found here: <https://github.com/INFO-523-SU25/final-project-castro/blob/main/src/Data_Exploration_MFG6G.ipynb>\n\n## Model Training\n\n<p style=\"text-align: justify;\">\n\nThe first objective of this study is to build a classification model for failures. The model will analyze data from table 1 to accurately predict the specific fails and failure type.\n\n</p>\n\n<p style=\"text-align: justify;\">\n\nThe initial model will be focused on predicting the Target feature as a binary classification, basically pass or fail based on the data set. Data was split using 70% for training and 30% for testing using stratify trying to maintain the distribution of 0/1s for each as data is highly imbalanced.\n\n</p>\n\n\n\n::::: columns\n::: column\n## AUC ROC Results\n\n::: {#cell-PMdata9 .cell message='false' execution_count=9}\n\n::: {#pmdata9 .cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>ROC_AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Nearest_Neighbors</td>\n      <td>0.784725</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gradient_Boosting</td>\n      <td>0.818907</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Decision_Tree</td>\n      <td>0.932831</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Extra_Trees</td>\n      <td>0.914466</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Random_Forest</td>\n      <td>0.972481</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Neural_Net</td>\n      <td>0.916352</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AdaBoost</td>\n      <td>0.899753</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Naive_Bayes</td>\n      <td>0.827014</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>QDA</td>\n      <td>0.857405</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LogisticRegression</td>\n      <td>0.880628</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTable 4. ROC AUC results for multiple models evaluated\n:::\n\n::: column\n## F1 Score Results\n\n::: {#cell-PMdata10 .cell message='false' execution_count=10}\n\n::: {#pmdata10 .cell-output .cell-output-display execution_count=10}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>f1 score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Nearest_Neighbors</td>\n      <td>0.423077</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gradient_Boosting</td>\n      <td>0.534884</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Decision_Tree</td>\n      <td>0.503145</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Extra_Trees</td>\n      <td>0.374101</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Random_Forest</td>\n      <td>0.567742</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Neural_Net</td>\n      <td>0.216667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>AdaBoost</td>\n      <td>0.473373</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Naive_Bayes</td>\n      <td>0.198758</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>QDA</td>\n      <td>0.386740</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>LogisticRegression</td>\n      <td>0.224000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTable 5. F1 Score for multiple models evaluated\n:::\n:::::\n\n<p style=\"text-align: justify;\">\n\nThis initial exploration for multiple models resulted in very high ROC_AUC scores for most of the models and not so great results for the F1 score. There are couple of key observations on these results, first models might be over-fitting the data resulting on these high scores and second because data is highly imbalaced models are great predicting 0s (good) as they represent majority of the sample but when looking at the F1 score the precision and recall for predicting the 1s is not the best. For the purposes of this study predicting the 1s (fails) is the main problem as these are the defects.\n\n</p>\n\n<p style=\"text-align: justify;\">\n\nBased on this initial results two models will be further evaluated Random Forest Classifer and XGBoost. Fine tuning hyperparameters and working multiple methods of sampling to reduce or manage the imbalance of the data.\n\n</p>\n\n<p style=\"text-align: justify;\">\n\nFor hyper-parameter tuning a combination of *sklearn.model_selection - GridSearchCV and RandomizedSearchCV* was used to run over multiple options.\n\n</p>\n\nFinal hyper-parameters for Random Forest Classifier Model:\n\n``` {#rf_hp .python}\n   model = RandomForestClassifier(n_estimators=50,\n                                   max_depth=10,\n                                   random_state=42,\n                                   max_features='log2',\n                                   min_samples_leaf=5,\n                                   min_samples_split=5)\n```\n\nResults for Random Forest Classifier Model:\n\n::: {#pmdata11 .cell message='false' execution_count=11}\n\n::: {.cell-output .cell-output-stdout}\n```\nRandomForestClassifier: ROC AUC on test dataset: 0.9751\nRandomForestClassifier: f1 score on test dataset: 0.6258\n```\n:::\n:::\n\n\nCross validation is used to understand if model is over-fitting:\n\n::: {#pmdata12 .cell message='false' execution_count=12}\n\n::: {.cell-output .cell-output-stdout}\n```\nCross validation results for Random Forest\nfit_time Cross Validation results 0.25\nscore_time Cross Validation results 0.01\ntest_accuracy Cross Validation results 0.90\ntrain_accuracy Cross Validation results 0.99\ntest_precision Cross Validation results 0.69\ntrain_precision Cross Validation results 0.97\ntest_recall Cross Validation results 0.46\ntrain_recall Cross Validation results 0.72\ntest_f1 Cross Validation results 0.45\ntrain_f1 Cross Validation results 0.83\ntest_roc_auc Cross Validation results 0.90\ntrain_roc_auc Cross Validation results 1.00\n```\n:::\n:::\n\n\n<p style=\"text-align: justify;\">\n\nAfter tuning model best F1 score obtain is 0.61. Cross-validation results are suggesting model is over-fitting and might not be able to generalize even the results from it are not great to identify failures.\n\n</p>\n\n<p style=\"text-align: justify;\">\n\nDifferent techniques were explored to if model would improve over-fitting and also F1-Score. Synthetic Minority Oversampling Technique (SMOTE) from the imblearn was used, intend of this method is over-sample the minority class creating synthetic data, results from this were worse than original model. Additionaly, under-sampling method RandomUnderSampler from same imblearn library was used on this case to reduce the sample of the majority class and try to balanced the data, results were also worse than original model.\n\n</p>\n\n<p style=\"text-align: justify;\">\n\nAdditionally to improve F1 score, a change on the probability threshold was explore, instead of using the normal 0.5, an analysis was done to estimate the ideal point for the best Random Forest model found (the tune original one).\n\n</p>\n\n::: {#cell-PMdata13 .cell message='false' execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata13-output-1.png){#pmdata13}\n:::\n:::\n\n\nFigure 6. Values of Recall, Precision and F1 Score metrics for every threshold.\n\n::::: columns\n::: column\n\n::: {#cell-PMdata14 .cell message='false' execution_count=14}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata14-output-1.png){#pmdata14}\n:::\n:::\n\n\nFigure 7. Confusion Matrix for results of Random Forest Classifier for default threshold 0.5.\n:::\n::: column\n\n::: {#cell-PMdata15 .cell message='false' execution_count=15}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata15-output-1.png){#pmdata15}\n:::\n:::\n\n\nFigure 8. Confusion Matrix for results of Random Forest Classifier for optimized threshold 0.28.\n:::\n:::::\n\n<p style=\"text-align: justify;\">\nAs observed on Figure 7 and 8, after improving the threshold based on the model results a balanced can be found between Precision and Recall. Now, this can be tune to improve one of them if the interest of the user is sacrifice over or under detecting.\n</p>\n\n<p style=\"text-align: justify;\">\nA second approach is to use XGboost, this model has the option to handle weights for each class. By adding a higher weight to the minority class, its expected to handle better the imbalanced on the dataset.\n</p>\n\nXGBoost Results:\n\n::: {#pmdata16 .cell message='false' execution_count=16}\n\n::: {.cell-output .cell-output-stdout}\n```\nF1 Score: 0.757\nCross validation results for Random Forest\nfit_time Cross Validation results 0.08\nscore_time Cross Validation results 0.01\ntest_accuracy Cross Validation results 0.98\ntrain_accuracy Cross Validation results 1.00\ntest_precision Cross Validation results 0.74\ntrain_precision Cross Validation results 1.00\ntest_recall Cross Validation results 0.72\ntrain_recall Cross Validation results 1.00\ntest_f1 Cross Validation results 0.73\ntrain_f1 Cross Validation results 1.00\ntest_roc_auc Cross Validation results 0.97\ntrain_roc_auc Cross Validation results 1.00\n```\n:::\n:::\n\n\n<p style=\"text-align: justify;\">\nF1 Score for XGboost without significant tuning and using weights is slightly better than the random forest model originally used. Cross Validation results still showing some level of over-fitting but improved from the original model. Hyperparameter tuning was done with similar approach as with random forest but not sigficant improvement was observed. \n</p>\n\n::: {#cell-PMdata17 .cell message='false' execution_count=17}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata17-output-1.png){#pmdata17}\n:::\n:::\n\n\nFigure 9. Confusion Matrix for results of XGBoost Model.\n\n<p style=\"text-align: justify;\">\nXGboost results are slighlty better than random forest optimized threshold model.\n</p>\n\n### Predicting the Failure Type\n\n<p style=\"text-align: justify;\">\nSince XGboost results were slighly better, this model will be used to go beyond the binary classification and try to predict the diffent failure mode. \n</p>\n\n::: {#cell-PMdata18 .cell message='false' execution_count=18}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata18-output-1.png){#pmdata18}\n:::\n:::\n\n\nFigure 10. Confusion Matrix results for XGBoost Multi-Class model.\n Class Names: 'Heat Dissipation Failure': 0, 'No Failure': 1, 'Overstrain Failure': 2, 'Power Failure': 3, 'Random Failures': 4, 'Tool Wear Failure': \n\n<p style=\"text-align: justify;\">\nOn this case for multi-class classification, the model was trained using the same parameters as before. The main different is how the weights (sample_weight paramater) was estimated, as there are more than 1 class an array was calculated, based on research a common way to calculate these weights is to count the ocurrence of classes and assign weights inversely proportional to this frequency.\n</p>\n\n<p style=\"text-align: justify;\">\nModel as with binary classification is great at predicting the majority (no Failure) on this case. Class 0 which is heat-disipation has a F1 Score of 0.68, Class 2: Overstrain Failure F1 score is 0.53 and Class 3: Power Failure is 0.77 which are similar to original 2 class results. However, on this case model is not able to predict class 4 and 5 (Random Failures,Tool Wear Failure), F1 score for those is 0.\n</p>\n\n<p style=\"text-align: justify;\">\nOne last important outcome of this models is understand what features are really important. Aside model performance is not great for all classes, understanding what features are important on the prediction model can help context experts to interprete results and take action to reduce fails and improve process overall. \n</p>\n\n::: {#cell-PMdata19 .cell message='false' execution_count=19}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata19-output-1.png){#pmdata19}\n:::\n:::\n\n\nDetailed Jupyter Notebook can be found here: https://github.com/INFO-523-SU25/final-project-castro/blob/main/src/Model_Training_PDM.ipynb \n\n### Time Series Analysis\n\n<p style=\"text-align: justify;\">The Second objective of this study which is also a important tool in manufacturing is how to use machine learning and data mining skills to detect outliers or anomalies in the process, a lot of the data that is streaming from equipment is time based, its collected or sampled with certain frequency. Anomaly detection is very valuable for the industry,having the ability of knowning when a machine or process is deviating for a 'normal' can help to stop and repair equipment quickly, reducing impact problems might have due downtimes and defects. </p>\n\n<p style=\"text-align: justify;\">After pre-processing the data study is focused on understand how algorithms like seasonal_decompose library and ARIMA (or auto_arima) can be used for anomaly detection. As initially observed, the data was randomly generated over a specific range, it does not follow a trend and there is no \"seasonality\" on it.</p>\n\n::: {#cell-PMdata20 .cell message='false' execution_count=20}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata20-output-1.png){#pmdata20}\n:::\n:::\n\n\nFigure 11. Results from Deasonal Decompose. Observed data (Original Data), trend (Smothed), seasonal (results from patter fount for the period defined) and Residual (Delta between original data and trend/season components)\n\n<p style=\"text-align: justify;\"> Assuming the decomposition is someone accurate we can use the residuals to define how each point is deviating from the was expected. Based on this assumption, a rule can be defined to identify was it abnormal behavior. </p>\n\n``` {#rf_hp .python}\n# Anomalies in residuals\nresiduals = decomposition.resid.dropna() #Obtain residuals from decompositions\nthreshold = 2 * residuals.std() # Our rule, on this cases based on research we selected to use 2X the standard deviation of the residuals\nanomalies = np.abs(residuals) > threshold # Applying the rule to obtain the anomalies\n```\n\n<p style=\"text-align: justify;\"> Second approach is to use ARIMA (Autoregressive Integrated Moving Average model). An ARIMA model is fit using Auto_Arima from pmdarima to facilitate the defination or P/D/Q values. Similar to other methods, after fitting model the calculate the difference between the actual values and predicted and define rules for this difference as done with the seasonal decompose. </p>\n\n::: {#pmdata21 .cell message='false' execution_count=21}\n\n::: {.cell-output .cell-output-stdout}\n```\n                               SARIMAX Results                                \n==============================================================================\nDep. Variable:                      y   No. Observations:                  139\nModel:                        SARIMAX   Log Likelihood                -149.194\nDate:                Thu, 14 Aug 2025   AIC                            302.388\nTime:                        13:56:08   BIC                            308.257\nSample:                    01-01-2024   HQIC                           304.773\n                         - 03-10-2024                                         \nCovariance Type:                  opg                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nintercept      5.8176      0.060     96.802      0.000       5.700       5.935\nsigma2         0.5010      0.059      8.537      0.000       0.386       0.616\n===================================================================================\nLjung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                 0.16\nProb(Q):                              0.98   Prob(JB):                         0.92\nHeteroskedasticity (H):               1.37   Skew:                             0.07\nProb(H) (two-sided):                  0.28   Kurtosis:                         3.10\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step).\nBest (p, d, q): (0, 0, 0)\n```\n:::\n:::\n\n\nTable 6. ARIMAX Results Summary\n\n::: {#cell-PMdata22 .cell message='false' execution_count=22}\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/pmdata22-output-1.png){#pmdata22}\n:::\n:::\n\n\nFigure 12. Results from ARIMA model and anomaly points detected based on pre-defined threshold of 2X the standard deviation of the residuals.\n\n## Results\n\n<p style=\"text-align: justify;\">\n\nThis will be the results section.\n\n</p>\n\n## Conclusions\n\n<p style=\"text-align: justify;\">\n\nThis will be the Conclusions section\n\n</p>\n\n## References\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}